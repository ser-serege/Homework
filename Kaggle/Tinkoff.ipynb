{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('credit_train.csv', sep=\";\",encoding='cp1251')\n",
    "test = pd.read_csv('credit_test.csv', sep=\";\",encoding='cp1251')\n",
    "le = preprocessing.LabelEncoder()\n",
    "train['gender']=le.fit_transform(train['gender'])\n",
    "train['marital_status']=le.fit_transform(train['marital_status'])\n",
    "train['job_position']=le.fit_transform(train['job_position'])\n",
    "train['education']=le.fit_transform(train['education'])\n",
    "train['tariff_id']=le.fit_transform(train['tariff_id'])\n",
    "\n",
    "list1 = list(train['living_region'].unique())\n",
    "\n",
    "town_encoded = dict(zip(list1, range(len(list1))))\n",
    "\n",
    "town_encoded\n",
    "\n",
    "df = pd.DataFrame.from_dict(town_encoded,orient='index')\n",
    "\n",
    "df = df.rename(columns={0:\"town\"})\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df['living_region']=df['index']\n",
    "\n",
    "df = df.drop('index',axis=1)\n",
    "\n",
    "\n",
    "fin_df = pd.merge(train,df, on='living_region')\n",
    "\n",
    "fin_df = fin_df.drop('living_region',axis=1)\n",
    "\n",
    "fin_df = fin_df.set_index('client_id')\n",
    "\n",
    "fin_df['credit_sum']=fin_df['credit_sum'].apply(lambda x: float(x.replace(',','.')))\n",
    "\n",
    "fin_df['score_shk']=fin_df['score_shk'].apply(lambda x: float(x.replace(',','.')))\n",
    "fin_df_train = fin_df\n",
    "\n",
    "train = test\n",
    "le = preprocessing.LabelEncoder()\n",
    "train['gender']=le.fit_transform(train['gender'])\n",
    "\n",
    "train['marital_status']=le.fit_transform(train['marital_status'])\n",
    "train['job_position']=le.fit_transform(train['job_position'])\n",
    "train['education']=le.fit_transform(train['education'])\n",
    "train['tariff_id']=le.fit_transform(train['tariff_id'])\n",
    "\n",
    "list1 = list(train['living_region'].unique())\n",
    "\n",
    "town_encoded = dict(zip(list1, range(len(list1))))\n",
    "\n",
    "town_encoded\n",
    "\n",
    "df = pd.DataFrame.from_dict(town_encoded,orient='index')\n",
    "\n",
    "df = df.rename(columns={0:\"town\"})\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df['living_region']=df['index']\n",
    "\n",
    "df = df.drop('index',axis=1)\n",
    "\n",
    "\n",
    "fin_df = pd.merge(train,df, on='living_region')\n",
    "\n",
    "fin_df = fin_df.drop('living_region',axis=1)\n",
    "\n",
    "fin_df = fin_df.set_index('client_id')\n",
    "\n",
    "fin_df['credit_sum']=fin_df['credit_sum'].apply(lambda x: float(x.replace(',','.')))\n",
    "\n",
    "fin_df['score_shk']=fin_df['score_shk'].apply(lambda x: float(x.replace(',','.')))\n",
    "\n",
    "fin_df_test = fin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Добавим новые, хорошо работающие фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df_test['money_while_credit']= fin_df_test['credit_month']*fin_df_test['monthly_income']\n",
    "fin_df_train['money_while_credit']= fin_df_train['credit_month']*fin_df_train['monthly_income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = fin_df_train['open_account_flg']\n",
    "X_train = fin_df_train.drop('open_account_flg',axis = 1)\n",
    "X_test = fin_df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Файл с блендингом разнородных моделей я не нашел, поэтому здесь представлен ансамбль из 3 xgboost-ов, который тоже отработал хорошо и вошел в финальный ансамбль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170746, 15)\n",
      "(91940, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1301) # seed to shuffle the train set\n",
    "\n",
    "n_folds = 5\n",
    "verbose = True\n",
    "shuffle = False\n",
    "\n",
    "training = fin_df_train\n",
    "test = fin_df_test\n",
    "print(training.shape)\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "X = fin_df_train.drop('open_account_flg',axis = 1)\n",
    "y = fin_df_train['open_account_flg']\n",
    "\n",
    "# Feature selection with xgboost feature selection\n",
    "\n",
    "\n",
    "X_sel = fin_df_train.drop('open_account_flg',axis = 1)\n",
    "sel_test = fin_df_test\n",
    "X, y, X_submission = np.array(X_sel), np.array(y), np.array(sel_test)\n",
    "\n",
    "if shuffle:\n",
    "    idx = np.random.permutation(y.size)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "#ratio = float(np.sum(y == 1)) / np.sum(y==0)\n",
    "clfs = [xgb.XGBClassifier(#base_score = 0.3,\n",
    "                     objective = \"binary:logistic\", \n",
    "                     max_depth = 18,\n",
    "                     n_estimators = 3021,\n",
    "                     learning_rate = 0.02, \n",
    "                     subsample = 0.85,\n",
    "                     colsample_bytree = 0.24,\n",
    "                     silent = 1,\n",
    "                     min_child_weight = 2,\n",
    "                     nthread = 5,\n",
    "                     gamma = 1.4,\n",
    "                     seed = 1301),\n",
    "        xgb.XGBClassifier(#base_score = 0.3,\n",
    "                     objective = \"binary:logistic\", \n",
    "                     max_depth = 7,\n",
    "                     n_estimators = 8511,\n",
    "                     learning_rate = 0.01, \n",
    "                     subsample = 0.6,\n",
    "                     colsample_bytree = 0.38,\n",
    "                     silent = 1,\n",
    "                     min_child_weight = 1,\n",
    "                     nthread = 5,\n",
    "                     gamma = 0.9,\n",
    "                     seed = 2017),\n",
    "        xgb.XGBClassifier(#base_score = 0.3,\n",
    "                     objective = \"binary:logistic\", \n",
    "                     max_depth = 15,\n",
    "                     n_estimators = 3021,\n",
    "                     learning_rate = 0.02, \n",
    "                     subsample = 0.85,\n",
    "                     colsample_bytree = 0.41,\n",
    "                     silent = 1,\n",
    "                     min_child_weight = 5,\n",
    "                     nthread = 5,\n",
    "                     gamma = 1.4,\n",
    "                     seed = 1347)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train and test sets for blending.\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating train and test sets for blending.\")\n",
    "        \n",
    "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((X_submission.shape[0], len(clfs)))\n",
    "skf = cross_validation.StratifiedKFold(y, n_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.24,\n",
      "       gamma=1.4, learning_rate=0.02, max_delta_step=0, max_depth=18,\n",
      "       min_child_weight=2, missing=None, n_estimators=3021, nthread=5,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=1301, silent=1, subsample=0.85)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "1 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.38,\n",
      "       gamma=0.9, learning_rate=0.01, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=8511, nthread=5,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=1, subsample=0.6)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "2 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.41,\n",
      "       gamma=1.4, learning_rate=0.02, max_delta_step=0, max_depth=15,\n",
      "       min_child_weight=5, missing=None, n_estimators=3021, nthread=5,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=1347, silent=1, subsample=0.85)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n"
     ]
    }
   ],
   "source": [
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf)\n",
    "    dataset_blend_test_j = np.zeros((X_submission.shape[0], n_folds))\n",
    "    for i, (train, testidx) in enumerate(skf):\n",
    "        print (\"Fold\", i)\n",
    "        X_train, y_train = X[train], y[train]\n",
    "        X_test, y_test = X[testidx], y[testidx]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_submission = clf.predict_proba(X_test)[:,1]\n",
    "        dataset_blend_train[testidx, j] = y_submission\n",
    "        dataset_blend_test_j[:, i] = clf.predict_proba(X_submission)[:,1]\n",
    "    dataset_blend_test[:,j] = dataset_blend_test_j.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сделаем блендинг и сохраним итоговый файл для сабмита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending.\n",
      "Linear stretch of predictions to [0,1]\n",
      "Saving Results.\n",
      "AUC= 0.765513500063\n"
     ]
    }
   ],
   "source": [
    "print (\"Blending.\")\n",
    "clf = LogisticRegression(C = 0.6, intercept_scaling = 0.5)\n",
    "clf.fit(dataset_blend_train, y)\n",
    "y_training = clf.predict_proba(dataset_blend_train)[:,1]\n",
    "y_submission = clf.predict_proba(dataset_blend_test)[:,1]\n",
    "    \n",
    "print (\"Linear stretch of predictions to [0,1]\")\n",
    "y_training = (y_training - y_training.min()) / (y_training.max() - y_training.min())\n",
    "y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
    "    \n",
    "print (\"Saving Results.\")\n",
    "submission = pd.DataFrame({\"_ID_\":test.index, \"_VAL_\":y_submission})\n",
    "submission.to_csv(\"submission_GBT_XGB.csv\", index=False)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_score = roc_auc_score(y, y_training)\n",
    "print (\"AUC=\", auc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
