{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.5\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.read.csv('/labs/laba03/lab10_test.csv', header=True)\n",
    "train = spark.read.csv('/labs/laba03/lab10_train.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.withColumn('user_id', train.user_id.cast(IntegerType()))\n",
    "train = train.withColumn('item_id', train.item_id.cast(IntegerType()))\n",
    "train = train.withColumn('purchase', train.item_id.cast(IntegerType()))\n",
    "test = test.withColumn('user_id', test.user_id.cast(IntegerType()))\n",
    "test = test.withColumn('item_id', test.item_id.cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = train.groupBy('user_id').sum('purchase').select('user_id', f.col('sum(purchase)').alias('sum_user'))\n",
    "item = train.groupBy('item_id').sum('purchase').select('item_id', f.col('sum(purchase)').alias('sum_item'))\n",
    "\n",
    "train2 = train .join(user, on='user_id', how='left')\\\n",
    "               .join(item, on='item_id', how='left')\n",
    "\n",
    "train2 = train2.fillna(0)\n",
    "train2 = train2.withColumn('targ', (f.col('sum_user') + f.col('sum_item')) / 2)\n",
    "train2 = train2.select('user_id', 'item_id', f.col('targ').alias('purchase'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 4 ms, total: 20 ms\n",
      "Wall time: 52.1 s\n"
     ]
    }
   ],
   "source": [
    "#0.910123208718 rank=15, maxIter=10, regParam=0.05, alpha=1.0\n",
    "als = ALS(coldStartStrategy=\"nan\",  rank=15, maxIter=10, regParam=0.05, alpha=1.0, \\\n",
    "          userCol='user_id', itemCol='item_id', ratingCol='purchase', \\\n",
    "          nonnegative=False, implicitPrefs=True, seed=871)\n",
    "%time als_model = als.fit(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = als_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@f.pandas_udf(FloatType())\n",
    "def to_probs(values):\n",
    "    return values.apply(lambda x: (x / 1.02))\n",
    "\n",
    "preds = predict_test.withColumn(\"purchase\", to_probs(f.col(\"prediction\")))\n",
    "preds = preds.sort(['user_id', 'item_id'], ascending=[True, True])\n",
    "\n",
    "preds.select('user_id', 'item_id', 'purchase').toPandas().to_csv('lab03_.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров по сетке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# The ALS instance\n",
    "als = ALS(userCol='user_id',\n",
    "          itemCol='item_id',\n",
    "          ratingCol='purchase',\n",
    "          nonnegative=False, \n",
    "          implicitPrefs=True,\n",
    "          coldStartStrategy=\"nan\",\n",
    "          seed=42)\n",
    "\n",
    "als_paramgrid = (ParamGridBuilder()\n",
    "                 .addGrid(als.rank, [6, 10, 15])\n",
    "                 .addGrid(als.maxIter, [10, 15])\n",
    "                 .addGrid(als.regParam, [0.1, 0.05, 0.15])\n",
    "                 .addGrid(als.alpha, [0.5, 1.0, 2.0, 3.0, 5.0])\n",
    "                 .build())\n",
    "\n",
    "# The evaluation function for determining the best model\n",
    "rmse_eval = RegressionEvaluator(labelCol='purchase',\n",
    "                                predictionCol='prediction', \n",
    "                                metricName='rmse')\n",
    "\n",
    "# The cross validation instance\n",
    "als_cv = CrossValidator(estimator=als,\n",
    "                        estimatorParamMaps=als_paramgrid,\n",
    "                        evaluator=rmse_eval,\n",
    "                        numFolds=2, \n",
    "                        seed=42)\n",
    "\n",
    "# Fit the models and find the best one!\n",
    "als_cv = als_cv.fit(train.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_best = als_cv.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = als_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@f.pandas_udf(FloatType())\n",
    "def to_probs(values):\n",
    "    return values.apply(lambda x: (x / 1.02))\n",
    "\n",
    "predAls = predict_test.withColumn(\"purchase\", to_probs(f.col(\"prediction\")))\n",
    "predAls = predAls.sort(['user_id', 'item_id'], ascending=[True, True])\n",
    "\n",
    "predAls.select('user_id', 'item_id', 'purchase').toPandas().to_csv('lab03_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
