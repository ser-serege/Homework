{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание к занятию «Обзор библиотеки XGBoost»\n",
    "\n",
    "#### Описание задания:\n",
    "\n",
    "1. Решите уже знакомую задачу регрессии — предсказание цены на недвижимость. Датасет — [train.csv](http://https//www.kaggle.com/c/house-prices-advanced-regression-techniques/data);\n",
    "2. Используйте objective = \"reg:linear\" в xgboost;\n",
    "3. Настройте гиперпараметры, используя hyperopt либо ручную настройку (как вам больше нравится);\n",
    "4. Используйте отложенную выборку (как на занятии), чтобы следить за процессом обучения xgboost'а, но — как и в предыдущем домашнем задании — финальную оценку качества давайте, используя 10-fold кросс-валидацию;\n",
    "5. Проанализируйте, насколько согласованы оценка на отложенной выборке и на кросс-валидации (одновременно уменьшаются/увеличиваются при изменении гиперпараметров или ведут себя по-разному);\n",
    "6. Проанализируйте признаки, используя XGBFI, сделайте выводы об интересных взаимодействиях;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на обучение и hold-out тест 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "splitter = ShuffleSplit(n_splits=1, test_size=0.3, random_state=777)\n",
    "\n",
    "for train_index, test_index in splitter.split(data, data.SalePrice):\n",
    "    d_train = data.iloc[train_index]\n",
    "    d_test = data.iloc[test_index]\n",
    "    \n",
    "    y_train = data['SalePrice'].iloc[train_index]\n",
    "    y_test = data['SalePrice'].iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы в разы не увеличивать число признаков при построении dummy, будем использовать категориальные признаки с < 30 уникальных значений\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = list(data.dtypes[data.dtypes == object].index)\n",
    "\n",
    "#закодируем пропущенные значений строкой, факт пропущенного значения тоже может нести в себе информацию\n",
    "data[cat_feat] = data[cat_feat].fillna('nan')\n",
    "\n",
    "#отфильтруем непрерывные признаки\n",
    "num_feat = [f for f in data if f not in (cat_feat + ['ID', 'SalePrice'])]\n",
    "\n",
    "cat_nunique = d_train[cat_feat].nunique()\n",
    "#print(cat_nunique)\n",
    "cat_feat = list(cat_nunique[cat_nunique < 30].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создаем признаки для \"деревянных\" моделей**\n",
    "\n",
    "1. Заменяем пропуски на специальное значение -999, чтобы деревья могли их отличить\n",
    "3. Создаем дамми-переменные для категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_train = pd.get_dummies(d_train[cat_feat], columns=cat_feat)\n",
    "dummy_test = pd.get_dummies(d_test[cat_feat], columns=cat_feat)\n",
    "\n",
    "dummy_cols = list(set(dummy_train) & set(dummy_test))\n",
    "\n",
    "dummy_train = dummy_train[dummy_cols]\n",
    "dummy_test = dummy_test[dummy_cols]\n",
    "\n",
    "\n",
    "X_train = pd.concat([d_train[num_feat].fillna(-999),\n",
    "                     dummy_train], axis=1)\n",
    "\n",
    "X_test = pd.concat([d_test[num_feat].fillna(-999),\n",
    "                     dummy_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важные гиперпараметры алгоритма**\n",
    "\n",
    "a. Параметры деревьев\n",
    "    1. max_depth - максимальная глубина дерева (обычно 3-10, больше глубина -> больше риск переобучения)\n",
    "    2. min_child_weight - минимальное число объектов в листе (обычно до 20, больше объектов -> меньше риск переобучения, но должен быть согласован с глубиной дерева)\n",
    "    3. gamma - минимально необходимый прирост качества для разбиения листа (редко используется)\n",
    "\n",
    "b. Параметры бустинга\n",
    "    0. objective - оптимизируемый функционал (встроен для классификации и регрессии, можно написать свой дифференцируемый)\n",
    "    1. n_estimators - кол-во базовых алгоритмов (чем меньше learning_rate, тем больше деревьев)\n",
    "    2. learning_rate - шаг создания ансамбля (зависит от n_estimators, но обычно 0.01 - 0.1)\n",
    "    2. colsample_bytree - доля признаков, случайно выбирающихся для построения дерева\n",
    "    3. subsample - доля объектов, случайно выбирающихся для построения дерева\n",
    "    4. n_jobs - кол-во потоков для одновременного построения деревьев (большая прибавка к скорости на многоядерных процах)\n",
    "    5. reg_alpha - вес L1 регуляризации (редко используется)\n",
    "    6. reg_lambda - вес L2 регуляризации (редко используется)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=4, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "          'objective':'reg:linear',\n",
    "          'n_estimators': 100,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 3,\n",
    "          'min_child_weight': 1,\n",
    "          'subsample': 1,\n",
    "          'colsample_bytree': 1,\n",
    "          'n_jobs': 4}\n",
    "\n",
    "\n",
    "rg_xgb = xgb.XGBRegressor(**params)\n",
    "rg_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_test = rg_xgb.predict(X_test)\n",
    "y_pred_xgb_train = rg_xgb.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среднеквадратическая ошибка на обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214336152.28028813"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_pred_xgb_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среднеквадратическая ошибка на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403867251.32861537"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_xgb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params :  {'colsample_bytree': 0.55, 'gamma': 0.9500000000000001, 'learning_rate': 0.03, 'max_depth': 9, 'min_child_weight': 7.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.5, 'n_jobs': -1}\n",
      "TEST mean squared error: 2401041399.1883\n",
      "Training with params :  {'colsample_bytree': 0.9500000000000001, 'gamma': 0.55, 'learning_rate': 0.03, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.9500000000000001, 'n_jobs': -1}\n",
      "TEST mean squared error: 2335749526.0504\n",
      "Training with params :  {'colsample_bytree': 0.55, 'gamma': 0.8500000000000001, 'learning_rate': 0.03, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.7000000000000001, 'n_jobs': -1}\n",
      "TEST mean squared error: 3201579530.3823\n",
      "Training with params :  {'colsample_bytree': 0.7000000000000001, 'gamma': 0.65, 'learning_rate': 0.03, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.9, 'n_jobs': -1}\n",
      "TEST mean squared error: 2357917695.4919\n",
      "Training with params :  {'colsample_bytree': 0.75, 'gamma': 0.9500000000000001, 'learning_rate': 0.03, 'max_depth': 4, 'min_child_weight': 5.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.55, 'n_jobs': -1}\n",
      "TEST mean squared error: 2386809674.2028\n",
      "Training with params :  {'colsample_bytree': 0.6000000000000001, 'gamma': 0.55, 'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 7.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.75, 'n_jobs': -1}\n",
      "TEST mean squared error: 2374137135.7349\n",
      "Training with params :  {'colsample_bytree': 0.8, 'gamma': 0.8500000000000001, 'learning_rate': 0.03, 'max_depth': 1, 'min_child_weight': 1.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.55, 'n_jobs': -1}\n",
      "TEST mean squared error: 3155089719.8432\n",
      "Training with params :  {'colsample_bytree': 0.5, 'gamma': 0.65, 'learning_rate': 0.03, 'max_depth': 7, 'min_child_weight': 7.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.75, 'n_jobs': -1}\n",
      "TEST mean squared error: 2325356846.2285\n",
      "Training with params :  {'colsample_bytree': 0.7000000000000001, 'gamma': 0.9, 'learning_rate': 0.03, 'max_depth': 8, 'min_child_weight': 3.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.8500000000000001, 'n_jobs': -1}\n",
      "TEST mean squared error: 2347685164.2814\n",
      "Training with params :  {'colsample_bytree': 0.65, 'gamma': 0.7000000000000001, 'learning_rate': 0.03, 'max_depth': 4, 'min_child_weight': 2.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.5, 'n_jobs': -1}\n",
      "TEST mean squared error: 2379108499.6170\n",
      "Training with params :  {'colsample_bytree': 0.7000000000000001, 'gamma': 0.6000000000000001, 'learning_rate': 0.03, 'max_depth': 4, 'min_child_weight': 6.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.55, 'n_jobs': -1}\n",
      "TEST mean squared error: 2372846297.0152\n",
      "Training with params :  {'colsample_bytree': 0.6000000000000001, 'gamma': 0.5, 'learning_rate': 0.03, 'max_depth': 9, 'min_child_weight': 8.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.55, 'n_jobs': -1}\n",
      "TEST mean squared error: 2361008920.9692\n",
      "Training with params :  {'colsample_bytree': 0.9, 'gamma': 0.9500000000000001, 'learning_rate': 0.03, 'max_depth': 7, 'min_child_weight': 9.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.6000000000000001, 'n_jobs': -1}\n",
      "TEST mean squared error: 2330084363.7848\n",
      "Training with params :  {'colsample_bytree': 0.75, 'gamma': 0.9, 'learning_rate': 0.03, 'max_depth': 10, 'min_child_weight': 3.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.7000000000000001, 'n_jobs': -1}\n",
      "TEST mean squared error: 2353021756.9380\n",
      "Training with params :  {'colsample_bytree': 0.65, 'gamma': 0.55, 'learning_rate': 0.03, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.65, 'n_jobs': -1}\n",
      "TEST mean squared error: 2373708561.2487\n",
      "Training with params :  {'colsample_bytree': 0.8500000000000001, 'gamma': 0.8500000000000001, 'learning_rate': 0.03, 'max_depth': 8, 'min_child_weight': 9.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.8500000000000001, 'n_jobs': -1}\n",
      "TEST mean squared error: 2305107877.2852\n",
      "Training with params :  {'colsample_bytree': 0.65, 'gamma': 0.65, 'learning_rate': 0.03, 'max_depth': 1, 'min_child_weight': 7.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.65, 'n_jobs': -1}\n",
      "TEST mean squared error: 3211536550.6977\n",
      "Training with params :  {'colsample_bytree': 0.6000000000000001, 'gamma': 0.55, 'learning_rate': 0.03, 'max_depth': 2, 'min_child_weight': 8.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.75, 'n_jobs': -1}\n",
      "TEST mean squared error: 2614959018.5389\n",
      "Training with params :  {'colsample_bytree': 0.8, 'gamma': 0.7000000000000001, 'learning_rate': 0.03, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.9500000000000001, 'n_jobs': -1}\n",
      "TEST mean squared error: 2272486540.8969\n",
      "Training with params :  {'colsample_bytree': 0.75, 'gamma': 0.75, 'learning_rate': 0.03, 'max_depth': 9, 'min_child_weight': 8.0, 'n_estimators': 50, 'silent': 1, 'subsample': 0.65, 'n_jobs': -1}\n",
      "TEST mean squared error: 2354730123.8096\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "\n",
    "#функция, которую будем МИНИМИЗИРОВАТЬ\n",
    "def score(params):\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['n_jobs'] = -1\n",
    "    print(\"Training with params : \", params)\n",
    "    clf = xgb.XGBRegressor(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_xgb_test = clf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred_xgb_test)\n",
    "    result = {'loss': mse, 'status': STATUS_OK}\n",
    "    print('TEST mean squared error: {0:.4f}'.format(mse))\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "space = {'max_depth' : hp.quniform('max_depth', 1, 10, 1),\n",
    "         'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "         'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "         'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "         'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "         'silent' : 1,\n",
    "         'n_estimators': 50,\n",
    "         'learning_rate': 0.03\n",
    "         }\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'gamma': 0.7000000000000001,\n",
       " 'max_depth': 7.0,\n",
       " 'min_child_weight': 2.0,\n",
       " 'subsample': 0.9500000000000001}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book_time': datetime.datetime(2018, 5, 5, 20, 16, 59, 454000),\n",
       " 'exp_key': None,\n",
       " 'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'idxs': {'colsample_bytree': [18],\n",
       "   'gamma': [18],\n",
       "   'max_depth': [18],\n",
       "   'min_child_weight': [18],\n",
       "   'subsample': [18]},\n",
       "  'tid': 18,\n",
       "  'vals': {'colsample_bytree': [0.8],\n",
       "   'gamma': [0.7000000000000001],\n",
       "   'max_depth': [7.0],\n",
       "   'min_child_weight': [2.0],\n",
       "   'subsample': [0.9500000000000001]},\n",
       "  'workdir': None},\n",
       " 'owner': None,\n",
       " 'refresh_time': datetime.datetime(2018, 5, 5, 20, 16, 59, 669000),\n",
       " 'result': {'loss': 2272486540.89688, 'status': 'ok'},\n",
       " 'spec': None,\n",
       " 'state': 2,\n",
       " 'tid': 18,\n",
       " 'version': 0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBFI\n",
    "\n",
    "Позволяет оценивать важности взаимодействия признаков\n",
    "\n",
    "https://github.com/limexp/xgbfir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проанализируем признаки, используя XGBFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgbfir\n",
    "xgbfir.saveXgbFI(rg_xgb, OutputXlsxFile='xgbfi_report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/util/_decorators.py:118: FutureWarning: The `sheetname` keyword is deprecated, use `sheet_name` instead\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interaction</th>\n",
       "      <th>Gain</th>\n",
       "      <th>FScore</th>\n",
       "      <th>wFScore</th>\n",
       "      <th>Average wFScore</th>\n",
       "      <th>Average Gain</th>\n",
       "      <th>Expected Gain</th>\n",
       "      <th>Gain Rank</th>\n",
       "      <th>FScore Rank</th>\n",
       "      <th>wFScore Rank</th>\n",
       "      <th>Avg wFScore Rank</th>\n",
       "      <th>Avg Gain Rank</th>\n",
       "      <th>Expected Gain Rank</th>\n",
       "      <th>Average Rank</th>\n",
       "      <th>Average Tree Index</th>\n",
       "      <th>Average Tree Depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>16895607971000</td>\n",
       "      <td>34</td>\n",
       "      <td>19.533268</td>\n",
       "      <td>0.574508</td>\n",
       "      <td>4.969296e+11</td>\n",
       "      <td>1.578298e+13</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>34.176471</td>\n",
       "      <td>1.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>3835829410000</td>\n",
       "      <td>58</td>\n",
       "      <td>26.306262</td>\n",
       "      <td>0.453556</td>\n",
       "      <td>6.613499e+10</td>\n",
       "      <td>1.792899e+12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>26.172414</td>\n",
       "      <td>1.465517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GarageCars</td>\n",
       "      <td>2223614240000</td>\n",
       "      <td>10</td>\n",
       "      <td>4.101761</td>\n",
       "      <td>0.410176</td>\n",
       "      <td>2.223614e+11</td>\n",
       "      <td>1.283884e+12</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BsmtFinSF1</td>\n",
       "      <td>2149223219000</td>\n",
       "      <td>48</td>\n",
       "      <td>19.324853</td>\n",
       "      <td>0.402601</td>\n",
       "      <td>4.477548e+10</td>\n",
       "      <td>9.554792e+11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>36.520833</td>\n",
       "      <td>1.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>1915425934000</td>\n",
       "      <td>34</td>\n",
       "      <td>15.354207</td>\n",
       "      <td>0.451594</td>\n",
       "      <td>5.633606e+10</td>\n",
       "      <td>1.470497e+12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>39.882353</td>\n",
       "      <td>1.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BsmtQual_Ex</td>\n",
       "      <td>1268563700000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.048924</td>\n",
       "      <td>0.762231</td>\n",
       "      <td>3.171409e+11</td>\n",
       "      <td>1.233063e+12</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>16.166667</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2ndFlrSF</td>\n",
       "      <td>941206220000</td>\n",
       "      <td>24</td>\n",
       "      <td>8.981409</td>\n",
       "      <td>0.374225</td>\n",
       "      <td>3.921693e+10</td>\n",
       "      <td>2.182794e+11</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>28.125000</td>\n",
       "      <td>1.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LotArea</td>\n",
       "      <td>779187813700</td>\n",
       "      <td>54</td>\n",
       "      <td>26.027397</td>\n",
       "      <td>0.481989</td>\n",
       "      <td>1.442940e+10</td>\n",
       "      <td>4.538190e+11</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>53.814815</td>\n",
       "      <td>1.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>YearRemodAdd</td>\n",
       "      <td>426437783000</td>\n",
       "      <td>19</td>\n",
       "      <td>8.354207</td>\n",
       "      <td>0.439695</td>\n",
       "      <td>2.244409e+10</td>\n",
       "      <td>2.786171e+11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>16.166667</td>\n",
       "      <td>43.894737</td>\n",
       "      <td>1.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>YearBuilt</td>\n",
       "      <td>345671924000</td>\n",
       "      <td>25</td>\n",
       "      <td>13.343444</td>\n",
       "      <td>0.533738</td>\n",
       "      <td>1.382688e+10</td>\n",
       "      <td>1.987015e+11</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>16.166667</td>\n",
       "      <td>50.240000</td>\n",
       "      <td>1.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fireplaces</td>\n",
       "      <td>336110750000</td>\n",
       "      <td>9</td>\n",
       "      <td>6.597847</td>\n",
       "      <td>0.733094</td>\n",
       "      <td>3.734564e+10</td>\n",
       "      <td>2.409926e+11</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>14.166667</td>\n",
       "      <td>34.888889</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KitchenQual_Ex</td>\n",
       "      <td>223306700000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.116534e+11</td>\n",
       "      <td>2.233067e+11</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OverallCond</td>\n",
       "      <td>221254014000</td>\n",
       "      <td>34</td>\n",
       "      <td>16.882583</td>\n",
       "      <td>0.496547</td>\n",
       "      <td>6.507471e+09</td>\n",
       "      <td>1.081121e+11</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>55.058824</td>\n",
       "      <td>1.382353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1stFlrSF</td>\n",
       "      <td>219730402000</td>\n",
       "      <td>18</td>\n",
       "      <td>4.401174</td>\n",
       "      <td>0.244510</td>\n",
       "      <td>1.220724e+10</td>\n",
       "      <td>5.177536e+10</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>52</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>25.333333</td>\n",
       "      <td>58.222222</td>\n",
       "      <td>1.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GarageType_Attchd</td>\n",
       "      <td>155534700000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.705479</td>\n",
       "      <td>0.568493</td>\n",
       "      <td>5.184490e+10</td>\n",
       "      <td>8.914686e+10</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BsmtExposure_Gd</td>\n",
       "      <td>151005200000</td>\n",
       "      <td>8</td>\n",
       "      <td>3.818004</td>\n",
       "      <td>0.477250</td>\n",
       "      <td>1.887565e+10</td>\n",
       "      <td>7.733319e+10</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>38.250000</td>\n",
       "      <td>1.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ExterQual_TA</td>\n",
       "      <td>144639042000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.421722</td>\n",
       "      <td>0.210861</td>\n",
       "      <td>7.231952e+10</td>\n",
       "      <td>5.942135e+10</td>\n",
       "      <td>17</td>\n",
       "      <td>48</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>33.833333</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GarageYrBlt</td>\n",
       "      <td>141851430000</td>\n",
       "      <td>14</td>\n",
       "      <td>5.610568</td>\n",
       "      <td>0.400755</td>\n",
       "      <td>1.013224e+10</td>\n",
       "      <td>6.175238e+10</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KitchenQual_TA</td>\n",
       "      <td>112199100000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>5.609955e+10</td>\n",
       "      <td>5.215124e+10</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>OpenPorchSF</td>\n",
       "      <td>107534190000</td>\n",
       "      <td>9</td>\n",
       "      <td>7.174168</td>\n",
       "      <td>0.797130</td>\n",
       "      <td>1.194824e+10</td>\n",
       "      <td>8.301937e+10</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>59.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BsmtQual_Gd</td>\n",
       "      <td>86107936000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.772994</td>\n",
       "      <td>0.193249</td>\n",
       "      <td>2.152698e+10</td>\n",
       "      <td>5.772061e+10</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>65.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Id</td>\n",
       "      <td>84477548600</td>\n",
       "      <td>26</td>\n",
       "      <td>2.240705</td>\n",
       "      <td>0.086181</td>\n",
       "      <td>3.249136e+09</td>\n",
       "      <td>4.497636e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>61</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>70.192308</td>\n",
       "      <td>1.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SaleType_New</td>\n",
       "      <td>81762370000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.781800</td>\n",
       "      <td>0.695450</td>\n",
       "      <td>2.044059e+10</td>\n",
       "      <td>6.726240e+10</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KitchenQual_Gd</td>\n",
       "      <td>79464400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925636</td>\n",
       "      <td>0.925636</td>\n",
       "      <td>7.946440e+10</td>\n",
       "      <td>7.355511e+10</td>\n",
       "      <td>24</td>\n",
       "      <td>63</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>28.166667</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CentralAir_Y</td>\n",
       "      <td>72337000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.679061</td>\n",
       "      <td>0.559687</td>\n",
       "      <td>2.411233e+10</td>\n",
       "      <td>4.206358e+10</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Neighborhood_OldTown</td>\n",
       "      <td>70600900000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.375734</td>\n",
       "      <td>0.187867</td>\n",
       "      <td>3.530045e+10</td>\n",
       "      <td>1.320881e+10</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>40.833333</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LotFrontage</td>\n",
       "      <td>70188854600</td>\n",
       "      <td>8</td>\n",
       "      <td>0.201566</td>\n",
       "      <td>0.025196</td>\n",
       "      <td>8.773607e+09</td>\n",
       "      <td>2.557694e+09</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "      <td>35</td>\n",
       "      <td>55</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>51.875000</td>\n",
       "      <td>1.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GarageArea</td>\n",
       "      <td>68447827000</td>\n",
       "      <td>15</td>\n",
       "      <td>6.510763</td>\n",
       "      <td>0.434051</td>\n",
       "      <td>4.563188e+09</td>\n",
       "      <td>3.091428e+10</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>27</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>62.133333</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BsmtExposure_No</td>\n",
       "      <td>65345990000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.380626</td>\n",
       "      <td>0.095157</td>\n",
       "      <td>1.633650e+10</td>\n",
       "      <td>7.127414e+09</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>47</td>\n",
       "      <td>42.166667</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ExterQual_Ex</td>\n",
       "      <td>61031200000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.103120e+10</td>\n",
       "      <td>6.103120e+10</td>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SaleCondition_Abnorml</td>\n",
       "      <td>7911470000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.681996</td>\n",
       "      <td>0.893999</td>\n",
       "      <td>2.637157e+09</td>\n",
       "      <td>7.068929e+09</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>SaleCondition_Normal</td>\n",
       "      <td>6180170000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.479452</td>\n",
       "      <td>0.239726</td>\n",
       "      <td>3.090085e+09</td>\n",
       "      <td>1.245403e+09</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>BsmtFullBath</td>\n",
       "      <td>5581830000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.146771</td>\n",
       "      <td>0.715590</td>\n",
       "      <td>1.860610e+09</td>\n",
       "      <td>3.874666e+09</td>\n",
       "      <td>59</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>69</td>\n",
       "      <td>53</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>82.333333</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>BsmtQual_TA</td>\n",
       "      <td>5496144000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.062622</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>1.374036e+09</td>\n",
       "      <td>8.604531e+07</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>82</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>BldgType_1Fam</td>\n",
       "      <td>5474300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840509</td>\n",
       "      <td>0.840509</td>\n",
       "      <td>5.474300e+09</td>\n",
       "      <td>4.601197e+09</td>\n",
       "      <td>61</td>\n",
       "      <td>69</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>41</td>\n",
       "      <td>49</td>\n",
       "      <td>47.333333</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>HeatingQC_Ex</td>\n",
       "      <td>5083709000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.122309</td>\n",
       "      <td>0.030577</td>\n",
       "      <td>1.270927e+09</td>\n",
       "      <td>1.764426e+08</td>\n",
       "      <td>62</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>68</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SaleCondition_Family</td>\n",
       "      <td>4661890000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>2.330945e+09</td>\n",
       "      <td>1.791122e+09</td>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>FireplaceQu_Ex</td>\n",
       "      <td>4590740000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.152642</td>\n",
       "      <td>0.050881</td>\n",
       "      <td>1.530247e+09</td>\n",
       "      <td>2.335797e+08</td>\n",
       "      <td>64</td>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>66</td>\n",
       "      <td>63.833333</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>SaleType_WD</td>\n",
       "      <td>4493110000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.775930</td>\n",
       "      <td>0.387965</td>\n",
       "      <td>2.246555e+09</td>\n",
       "      <td>1.810321e+09</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>BsmtExposure_Av</td>\n",
       "      <td>4466020000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>2.233010e+09</td>\n",
       "      <td>3.739852e+08</td>\n",
       "      <td>66</td>\n",
       "      <td>59</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>65</td>\n",
       "      <td>62.333333</td>\n",
       "      <td>89.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Neighborhood_NridgHt</td>\n",
       "      <td>4221180000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.959883</td>\n",
       "      <td>0.979941</td>\n",
       "      <td>2.110590e+09</td>\n",
       "      <td>4.111038e+09</td>\n",
       "      <td>67</td>\n",
       "      <td>60</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>63</td>\n",
       "      <td>52</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>YrSold</td>\n",
       "      <td>4170960000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100783</td>\n",
       "      <td>0.050391</td>\n",
       "      <td>2.085480e+09</td>\n",
       "      <td>2.189847e+08</td>\n",
       "      <td>68</td>\n",
       "      <td>61</td>\n",
       "      <td>68</td>\n",
       "      <td>74</td>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Exterior2nd_AsbShng</td>\n",
       "      <td>3072960000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113503</td>\n",
       "      <td>0.056751</td>\n",
       "      <td>1.536480e+09</td>\n",
       "      <td>1.731829e+08</td>\n",
       "      <td>69</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "      <td>68.166667</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>EnclosedPorch</td>\n",
       "      <td>2695070000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>2.695070e+09</td>\n",
       "      <td>4.219288e+07</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>53</td>\n",
       "      <td>81</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Neighborhood_BrkSide</td>\n",
       "      <td>2327240000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951076</td>\n",
       "      <td>0.951076</td>\n",
       "      <td>2.327240e+09</td>\n",
       "      <td>2.213383e+09</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>58</td>\n",
       "      <td>52.666667</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Exterior1st_AsbShng</td>\n",
       "      <td>2018780000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>2.018780e+09</td>\n",
       "      <td>1.185194e+08</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>75</td>\n",
       "      <td>69</td>\n",
       "      <td>65</td>\n",
       "      <td>72</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>MasVnrType_BrkFace</td>\n",
       "      <td>1963300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029354</td>\n",
       "      <td>0.029354</td>\n",
       "      <td>1.963300e+09</td>\n",
       "      <td>5.763112e+07</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>78</td>\n",
       "      <td>67</td>\n",
       "      <td>78</td>\n",
       "      <td>74.833333</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>MSZoning_FV</td>\n",
       "      <td>1915020000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998043</td>\n",
       "      <td>0.998043</td>\n",
       "      <td>1.915020e+09</td>\n",
       "      <td>1.911272e+09</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>54.333333</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Heating_GasA</td>\n",
       "      <td>1490250000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.114481</td>\n",
       "      <td>0.114481</td>\n",
       "      <td>1.490250e+09</td>\n",
       "      <td>1.706059e+08</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>66</td>\n",
       "      <td>58</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Neighborhood_ClearCr</td>\n",
       "      <td>1256450000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>1.256450e+09</td>\n",
       "      <td>7.376419e+07</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Exterior1st_VinylSd</td>\n",
       "      <td>1114130000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.072407</td>\n",
       "      <td>0.072407</td>\n",
       "      <td>1.114130e+09</td>\n",
       "      <td>8.067086e+07</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Condition1_PosA</td>\n",
       "      <td>1041640000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074364</td>\n",
       "      <td>0.074364</td>\n",
       "      <td>1.041640e+09</td>\n",
       "      <td>7.746051e+07</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>70</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>73.833333</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>HouseStyle_1.5Fin</td>\n",
       "      <td>992218000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050881</td>\n",
       "      <td>0.050881</td>\n",
       "      <td>9.922180e+08</td>\n",
       "      <td>5.048467e+07</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>77.833333</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>RoofMatl_CompShg</td>\n",
       "      <td>871342000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066536</td>\n",
       "      <td>0.066536</td>\n",
       "      <td>8.713420e+08</td>\n",
       "      <td>5.797579e+07</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>67</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>76.166667</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Exterior2nd_VinylSd</td>\n",
       "      <td>786218000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067515</td>\n",
       "      <td>0.067515</td>\n",
       "      <td>7.862180e+08</td>\n",
       "      <td>5.308125e+07</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>66</td>\n",
       "      <td>81</td>\n",
       "      <td>79</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>BsmtFinSF2</td>\n",
       "      <td>515629000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037182</td>\n",
       "      <td>0.037182</td>\n",
       "      <td>5.156290e+08</td>\n",
       "      <td>1.917212e+07</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>80.166667</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>BsmtHalfBath</td>\n",
       "      <td>179704000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>1.797040e+08</td>\n",
       "      <td>1.055014e+06</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>GarageQual_Fa</td>\n",
       "      <td>153609000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>1.536090e+08</td>\n",
       "      <td>3.306652e+06</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Functional_Mod</td>\n",
       "      <td>104978000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>1.049780e+08</td>\n",
       "      <td>1.643491e+06</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>GarageQual_TA</td>\n",
       "      <td>97697100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>9.769710e+07</td>\n",
       "      <td>5.735642e+05</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Interaction            Gain  FScore    wFScore  Average wFScore  \\\n",
       "0             OverallQual  16895607971000      34  19.533268         0.574508   \n",
       "1               GrLivArea   3835829410000      58  26.306262         0.453556   \n",
       "2              GarageCars   2223614240000      10   4.101761         0.410176   \n",
       "3              BsmtFinSF1   2149223219000      48  19.324853         0.402601   \n",
       "4             TotalBsmtSF   1915425934000      34  15.354207         0.451594   \n",
       "5             BsmtQual_Ex   1268563700000       4   3.048924         0.762231   \n",
       "6                2ndFlrSF    941206220000      24   8.981409         0.374225   \n",
       "7                 LotArea    779187813700      54  26.027397         0.481989   \n",
       "8            YearRemodAdd    426437783000      19   8.354207         0.439695   \n",
       "9               YearBuilt    345671924000      25  13.343444         0.533738   \n",
       "10             Fireplaces    336110750000       9   6.597847         0.733094   \n",
       "11         KitchenQual_Ex    223306700000       2   2.000000         1.000000   \n",
       "12            OverallCond    221254014000      34  16.882583         0.496547   \n",
       "13               1stFlrSF    219730402000      18   4.401174         0.244510   \n",
       "14      GarageType_Attchd    155534700000       3   1.705479         0.568493   \n",
       "15        BsmtExposure_Gd    151005200000       8   3.818004         0.477250   \n",
       "16           ExterQual_TA    144639042000       2   0.421722         0.210861   \n",
       "17            GarageYrBlt    141851430000      14   5.610568         0.400755   \n",
       "18         KitchenQual_TA    112199100000       2   0.785714         0.392857   \n",
       "19            OpenPorchSF    107534190000       9   7.174168         0.797130   \n",
       "20            BsmtQual_Gd     86107936000       4   0.772994         0.193249   \n",
       "21                     Id     84477548600      26   2.240705         0.086181   \n",
       "22           SaleType_New     81762370000       4   2.781800         0.695450   \n",
       "23         KitchenQual_Gd     79464400000       1   0.925636         0.925636   \n",
       "24           CentralAir_Y     72337000000       3   1.679061         0.559687   \n",
       "25   Neighborhood_OldTown     70600900000       2   0.375734         0.187867   \n",
       "26            LotFrontage     70188854600       8   0.201566         0.025196   \n",
       "27             GarageArea     68447827000      15   6.510763         0.434051   \n",
       "28        BsmtExposure_No     65345990000       4   0.380626         0.095157   \n",
       "29           ExterQual_Ex     61031200000       1   1.000000         1.000000   \n",
       "..                    ...             ...     ...        ...              ...   \n",
       "56  SaleCondition_Abnorml      7911470000       3   2.681996         0.893999   \n",
       "57   SaleCondition_Normal      6180170000       2   0.479452         0.239726   \n",
       "58           BsmtFullBath      5581830000       3   2.146771         0.715590   \n",
       "59            BsmtQual_TA      5496144000       4   0.062622         0.015656   \n",
       "60          BldgType_1Fam      5474300000       1   0.840509         0.840509   \n",
       "61           HeatingQC_Ex      5083709000       4   0.122309         0.030577   \n",
       "62   SaleCondition_Family      4661890000       2   0.780822         0.390411   \n",
       "63         FireplaceQu_Ex      4590740000       3   0.152642         0.050881   \n",
       "64            SaleType_WD      4493110000       2   0.775930         0.387965   \n",
       "65        BsmtExposure_Av      4466020000       2   0.164384         0.082192   \n",
       "66   Neighborhood_NridgHt      4221180000       2   1.959883         0.979941   \n",
       "67                 YrSold      4170960000       2   0.100783         0.050391   \n",
       "68    Exterior2nd_AsbShng      3072960000       2   0.113503         0.056751   \n",
       "69          EnclosedPorch      2695070000       1   0.015656         0.015656   \n",
       "70   Neighborhood_BrkSide      2327240000       1   0.951076         0.951076   \n",
       "71    Exterior1st_AsbShng      2018780000       1   0.058708         0.058708   \n",
       "72     MasVnrType_BrkFace      1963300000       1   0.029354         0.029354   \n",
       "73            MSZoning_FV      1915020000       1   0.998043         0.998043   \n",
       "74           Heating_GasA      1490250000       1   0.114481         0.114481   \n",
       "75   Neighborhood_ClearCr      1256450000       1   0.058708         0.058708   \n",
       "76    Exterior1st_VinylSd      1114130000       1   0.072407         0.072407   \n",
       "77        Condition1_PosA      1041640000       1   0.074364         0.074364   \n",
       "78      HouseStyle_1.5Fin       992218000       1   0.050881         0.050881   \n",
       "79       RoofMatl_CompShg       871342000       1   0.066536         0.066536   \n",
       "80    Exterior2nd_VinylSd       786218000       1   0.067515         0.067515   \n",
       "81             BsmtFinSF2       515629000       1   0.037182         0.037182   \n",
       "82           BsmtHalfBath       179704000       1   0.005871         0.005871   \n",
       "83          GarageQual_Fa       153609000       1   0.021526         0.021526   \n",
       "84         Functional_Mod       104978000       1   0.015656         0.015656   \n",
       "85          GarageQual_TA        97697100       1   0.005871         0.005871   \n",
       "\n",
       "    Average Gain  Expected Gain  Gain Rank  FScore Rank  wFScore Rank  \\\n",
       "0   4.969296e+11   1.578298e+13          1            4             3   \n",
       "1   6.613499e+10   1.792899e+12          2            1             1   \n",
       "2   2.223614e+11   1.283884e+12          3           15            22   \n",
       "3   4.477548e+10   9.554792e+11          4            3             4   \n",
       "4   5.633606e+10   1.470497e+12          5            5             6   \n",
       "5   3.171409e+11   1.233063e+12          6           33            31   \n",
       "6   3.921693e+10   2.182794e+11          7            9             8   \n",
       "7   1.442940e+10   4.538190e+11          8            2             2   \n",
       "8   2.244409e+10   2.786171e+11          9           10            10   \n",
       "9   1.382688e+10   1.987015e+11         10            8             7   \n",
       "10  3.734564e+10   2.409926e+11         11           16            12   \n",
       "11  1.116534e+11   2.233067e+11         12           47            37   \n",
       "12  6.507471e+09   1.081121e+11         13            6             5   \n",
       "13  1.220724e+10   5.177536e+10         14           11            21   \n",
       "14  5.184490e+10   8.914686e+10         15           41            40   \n",
       "15  1.887565e+10   7.733319e+10         16           21            27   \n",
       "16  7.231952e+10   5.942135e+10         17           48            57   \n",
       "17  1.013224e+10   6.175238e+10         18           14            15   \n",
       "18  5.609955e+10   5.215124e+10         19           49            51   \n",
       "19  1.194824e+10   8.301937e+10         20           17            11   \n",
       "20  2.152698e+10   5.772061e+10         21           34            54   \n",
       "21  3.249136e+09   4.497636e+09         22            7            35   \n",
       "22  2.044059e+10   6.726240e+10         23           35            32   \n",
       "23  7.946440e+10   7.355511e+10         24           63            49   \n",
       "24  2.411233e+10   4.206358e+10         25           42            42   \n",
       "25  3.530045e+10   1.320881e+10         26           50            59   \n",
       "26  8.773607e+09   2.557694e+09         27           22            60   \n",
       "27  4.563188e+09   3.091428e+10         28           12            13   \n",
       "28  1.633650e+10   7.127414e+09         29           36            58   \n",
       "29  6.103120e+10   6.103120e+10         30           64            46   \n",
       "..           ...            ...        ...          ...           ...   \n",
       "56  2.637157e+09   7.068929e+09         57           44            33   \n",
       "57  3.090085e+09   1.245403e+09         58           56            56   \n",
       "58  1.860610e+09   3.874666e+09         59           45            36   \n",
       "59  1.374036e+09   8.604531e+07         60           39            74   \n",
       "60  5.474300e+09   4.601197e+09         61           69            50   \n",
       "61  1.270927e+09   1.764426e+08         62           40            64   \n",
       "62  2.330945e+09   1.791122e+09         63           57            52   \n",
       "63  1.530247e+09   2.335797e+08         64           46            63   \n",
       "64  2.246555e+09   1.810321e+09         65           58            53   \n",
       "65  2.233010e+09   3.739852e+08         66           59            61   \n",
       "66  2.110590e+09   4.111038e+09         67           60            38   \n",
       "67  2.085480e+09   2.189847e+08         68           61            68   \n",
       "68  1.536480e+09   1.731829e+08         69           62            67   \n",
       "69  2.695070e+09   4.219288e+07         70           70            83   \n",
       "70  2.327240e+09   2.213383e+09         71           71            48   \n",
       "71  2.018780e+09   1.185194e+08         72           72            75   \n",
       "72  1.963300e+09   5.763112e+07         73           73            80   \n",
       "73  1.915020e+09   1.911272e+09         74           74            47   \n",
       "74  1.490250e+09   1.706059e+08         75           75            66   \n",
       "75  1.256450e+09   7.376419e+07         76           76            76   \n",
       "76  1.114130e+09   8.067086e+07         77           77            71   \n",
       "77  1.041640e+09   7.746051e+07         78           78            70   \n",
       "78  9.922180e+08   5.048467e+07         79           79            77   \n",
       "79  8.713420e+08   5.797579e+07         80           80            73   \n",
       "80  7.862180e+08   5.308125e+07         81           81            72   \n",
       "81  5.156290e+08   1.917212e+07         82           82            78   \n",
       "82  1.797040e+08   1.055014e+06         83           83            85   \n",
       "83  1.536090e+08   3.306652e+06         84           84            81   \n",
       "84  1.049780e+08   1.643491e+06         85           85            84   \n",
       "85  9.769710e+07   5.735642e+05         86           86            86   \n",
       "\n",
       "    Avg wFScore Rank  Avg Gain Rank  Expected Gain Rank  Average Rank  \\\n",
       "0                 28              1                   1      6.333333   \n",
       "1                 39              7                   2      8.666667   \n",
       "2                 43              3                   4     15.000000   \n",
       "3                 45             13                   6     12.500000   \n",
       "4                 40              9                   3     11.333333   \n",
       "5                 20              2                   5     16.166667   \n",
       "6                 50             14                  11     16.500000   \n",
       "7                 37             26                   7     13.666667   \n",
       "8                 41             19                   8     16.166667   \n",
       "9                 33             27                  12     16.166667   \n",
       "10                22             15                   9     14.166667   \n",
       "11                 1              4                  10     18.500000   \n",
       "12                36             39                  13     18.666667   \n",
       "13                52             30                  24     25.333333   \n",
       "14                29             11                  14     25.000000   \n",
       "15                38             22                  16     23.333333   \n",
       "16                54              6                  21     33.833333   \n",
       "17                46             34                  19     24.333333   \n",
       "18                47             10                  23     33.166667   \n",
       "19                17             31                  15     18.500000   \n",
       "20                55             20                  22     34.333333   \n",
       "21                61             45                  50     36.666667   \n",
       "22                25             21                  18     25.666667   \n",
       "23                11              5                  17     28.166667   \n",
       "24                30             18                  26     30.500000   \n",
       "25                56             16                  38     40.833333   \n",
       "26                79             35                  55     46.333333   \n",
       "27                42             43                  27     27.500000   \n",
       "28                60             23                  47     42.166667   \n",
       "29                 2              8                  20     28.333333   \n",
       "..               ...            ...                 ...           ...   \n",
       "56                12             54                  48     41.333333   \n",
       "57                53             46                  63     55.333333   \n",
       "58                23             69                  53     47.500000   \n",
       "59                82             74                  73     67.000000   \n",
       "60                14             41                  49     47.333333   \n",
       "61                77             75                  68     64.333333   \n",
       "62                48             58                  61     56.500000   \n",
       "63                72             72                  66     63.833333   \n",
       "64                49             60                  60     57.500000   \n",
       "65                62             61                  65     62.333333   \n",
       "66                 6             63                  52     47.666667   \n",
       "67                74             64                  67     67.000000   \n",
       "68                71             71                  69     68.166667   \n",
       "69                83             53                  81     73.333333   \n",
       "70                 9             59                  58     52.666667   \n",
       "71                69             65                  72     70.833333   \n",
       "72                78             67                  78     74.833333   \n",
       "73                 4             68                  59     54.333333   \n",
       "74                58             73                  70     69.500000   \n",
       "75                70             76                  76     75.000000   \n",
       "76                65             77                  74     73.500000   \n",
       "77                64             78                  75     73.833333   \n",
       "78                73             79                  80     77.833333   \n",
       "79                67             80                  77     76.166667   \n",
       "80                66             81                  79     76.666667   \n",
       "81                75             82                  82     80.166667   \n",
       "82                85             83                  85     84.000000   \n",
       "83                80             84                  83     82.666667   \n",
       "84                84             85                  84     84.500000   \n",
       "85                86             86                  86     86.000000   \n",
       "\n",
       "    Average Tree Index  Average Tree Depth  \n",
       "0            34.176471            1.029412  \n",
       "1            26.172414            1.465517  \n",
       "2            18.700000            1.300000  \n",
       "3            36.520833            1.541667  \n",
       "4            39.882353            1.176471  \n",
       "5            12.250000            0.500000  \n",
       "6            28.125000            1.375000  \n",
       "7            53.814815            1.296296  \n",
       "8            43.894737            1.368421  \n",
       "9            50.240000            1.520000  \n",
       "10           34.888889            0.666667  \n",
       "11           20.000000            0.000000  \n",
       "12           55.058824            1.382353  \n",
       "13           58.222222            1.611111  \n",
       "14           11.000000            2.000000  \n",
       "15           38.250000            1.125000  \n",
       "16           30.000000            2.000000  \n",
       "17           43.000000            1.357143  \n",
       "18           12.500000            2.000000  \n",
       "19           59.777778            0.777778  \n",
       "20           65.750000            2.000000  \n",
       "21           70.192308            1.846154  \n",
       "22           32.250000            1.500000  \n",
       "23           18.000000            1.000000  \n",
       "24           22.333333            2.000000  \n",
       "25           13.000000            2.000000  \n",
       "26           51.875000            1.875000  \n",
       "27           62.133333            1.400000  \n",
       "28           31.500000            1.500000  \n",
       "29           24.000000            0.000000  \n",
       "..                 ...                 ...  \n",
       "56           72.000000            1.333333  \n",
       "57           60.000000            2.000000  \n",
       "58           82.333333            1.333333  \n",
       "59           57.000000            2.000000  \n",
       "60           46.000000            2.000000  \n",
       "61           61.750000            2.000000  \n",
       "62           91.000000            1.500000  \n",
       "63           53.333333            2.000000  \n",
       "64           83.000000            2.000000  \n",
       "65           89.500000            2.000000  \n",
       "66           78.500000            1.000000  \n",
       "67           73.500000            2.000000  \n",
       "68           46.500000            1.500000  \n",
       "69           40.000000            2.000000  \n",
       "70           83.000000            2.000000  \n",
       "71           80.000000            2.000000  \n",
       "72           95.000000            1.000000  \n",
       "73           74.000000            1.000000  \n",
       "74           57.000000            2.000000  \n",
       "75           71.000000            2.000000  \n",
       "76           91.000000            2.000000  \n",
       "77           91.000000            1.000000  \n",
       "78           68.000000            2.000000  \n",
       "79           88.000000            1.000000  \n",
       "80           48.000000            2.000000  \n",
       "81           48.000000            2.000000  \n",
       "82           93.000000            2.000000  \n",
       "83           98.000000            2.000000  \n",
       "84           81.000000            2.000000  \n",
       "85           76.000000            2.000000  \n",
       "\n",
       "[86 rows x 16 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel('xgbfi_report.xlsx', sheetname=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Используйте отложенную выборку (как на занятии), чтобы следить за процессом обучения xgboost'а, но — как и в предыдущем домашнем задании — финальную оценку качества давайте, используя 10-fold кросс-валидацию;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "  2%|▏         | 1/43 [00:00<00:11,  3.71it/s]/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "100%|██████████| 43/43 [00:07<00:00,  5.81it/s]\n"
     ]
    }
   ],
   "source": [
    "class MeanClassifier():\n",
    "    def __init__(self, col):\n",
    "        self._col = col\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self._y_mean = y.mean()\n",
    "        self._means = y.groupby(X[self._col].astype(str)).mean()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        new_feature = X[self._col].astype(str)\\\n",
    "            .map(self._means.to_dict())\\\n",
    "            .fillna(self._y_mean)\n",
    "        return np.stack([1-new_feature, new_feature], axis=1)\n",
    "    \n",
    "    \n",
    "def get_meta_features(clf, X_train, y_train, X_test, stack_cv):\n",
    "    meta_train = np.zeros_like(y_train, dtype=float)\n",
    "    meta_test = np.zeros_like(y_test, dtype=float)\n",
    "    \n",
    "    for i, (train_ind, test_ind) in enumerate(stack_cv.split(X_train, y_train)):\n",
    "        \n",
    "        clf.fit(X_train.iloc[train_ind], y_train.iloc[train_ind])\n",
    "        meta_train[test_ind] = clf.predict_proba(X_train.iloc[test_ind])[:, 1]\n",
    "        meta_test += clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return meta_train, meta_test / stack_cv.n_splits\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "stack_cv = StratifiedKFold(n_splits=10, random_state=555)\n",
    "\n",
    "meta_train = []\n",
    "meta_test = []\n",
    "col_names = []\n",
    "\n",
    "for c in tqdm.tqdm(cat_nunique.index.tolist()):\n",
    "    clf = MeanClassifier(c)\n",
    "    \n",
    "    meta_tr, meta_te = get_meta_features(clf, d_train, y_train, d_test, stack_cv)\n",
    "\n",
    "    meta_train.append(meta_tr)\n",
    "    meta_test.append(meta_te)\n",
    "    col_names.append('mean_pred_{}'.format(c))\n",
    "\n",
    "X_mean_train = pd.DataFrame(np.stack(meta_train, axis=1), columns=col_names, index=d_train.index)\n",
    "X_mean_test = pd.DataFrame(np.stack(meta_test, axis=1), columns=col_names, index=d_test.index)\n",
    "\n",
    "X_train = pd.concat([X_train, X_mean_train], axis=1)\n",
    "X_test = pd.concat([X_test, X_mean_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'n_estimators': 50,\n",
    "          'learning_rate': 0.03,\n",
    "          'max_depth': 5,\n",
    "          'min_child_weight': 1,\n",
    "          'subsample': 0.8,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'n_jobs': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем функцию, похожую на GridSearchCV, только для одной отложенной выборки X_test. Она перебирает параметки по заданной сетке и возврашает лучшие по ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_params(clf, param_grid):\n",
    "    clf = GridSearchCV(clf, param_grid, cv=[(np.arange(len(X_train)),\n",
    "                                                               np.arange(len(X_test)) + len(X_train))],\n",
    "                  verbose=3)\n",
    "\n",
    "    clf.fit(pd.concat([X_train, X_test]).values, pd.concat([y_train, y_test]).values)\n",
    "    best_params = clf.best_estimator_.get_params()\n",
    "    print('Best params: ', best_params)\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбираем max_depth и min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 9 candidates, totalling 9 fits\n",
      "[CV] max_depth=3, min_child_weight=10 ................................\n",
      "[CV]  max_depth=3, min_child_weight=10, score=0.5058932223455579, total=   0.1s\n",
      "[CV] max_depth=3, min_child_weight=20 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_child_weight=20, score=0.5359376878522844, total=   0.1s\n",
      "[CV] max_depth=3, min_child_weight=100 ...............................\n",
      "[CV]  max_depth=3, min_child_weight=100, score=0.5002286329833703, total=   0.1s\n",
      "[CV] max_depth=5, min_child_weight=10 ................................\n",
      "[CV]  max_depth=5, min_child_weight=10, score=0.5148607280823831, total=   0.2s\n",
      "[CV] max_depth=5, min_child_weight=20 ................................\n",
      "[CV]  max_depth=5, min_child_weight=20, score=0.5458929720982357, total=   0.2s\n",
      "[CV] max_depth=5, min_child_weight=100 ...............................\n",
      "[CV]  max_depth=5, min_child_weight=100, score=0.5039651312098363, total=   0.2s\n",
      "[CV] max_depth=10, min_child_weight=10 ...............................\n",
      "[CV]  max_depth=10, min_child_weight=10, score=0.518735905352752, total=   0.3s\n",
      "[CV] max_depth=10, min_child_weight=20 ...............................\n",
      "[CV]  max_depth=10, min_child_weight=20, score=0.5487967519402525, total=   0.2s\n",
      "[CV] max_depth=10, min_child_weight=100 ..............................\n",
      "[CV]  max_depth=10, min_child_weight=100, score=0.5039651312098363, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.03, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 20, 'missing': None, 'n_estimators': 50, 'n_jobs': 4, 'nthread': None, 'objective': 'reg:linear', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rg_xgb = xgb.XGBRegressor(**best_params)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_child_weight': [10, 20, 100]#[1, 5, 10]\n",
    "}\n",
    "\n",
    "best_params = find_params(rg_xgb, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбираем gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 5 candidates, totalling 5 fits\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] .............. gamma=0.0, score=0.5487967519402525, total=   0.2s\n",
      "[CV] gamma=0.125 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ gamma=0.125, score=0.5487967519402525, total=   0.2s\n",
      "[CV] gamma=0.25 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. gamma=0.25, score=0.5487967519402525, total=   0.2s\n",
      "[CV] gamma=0.375 .....................................................\n",
      "[CV] ............ gamma=0.375, score=0.5487967519402525, total=   0.2s\n",
      "[CV] gamma=0.5 .......................................................\n",
      "[CV] .............. gamma=0.5, score=0.5487967519402525, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0.0, 'learning_rate': 0.03, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 20, 'missing': None, 'n_estimators': 50, 'n_jobs': 4, 'nthread': None, 'objective': 'reg:linear', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "rg_xgb = xgb.XGBRegressor(**best_params)\n",
    "\n",
    "param_grid = {\n",
    "    'gamma': np.linspace(0, 0.5, 5)\n",
    "}\n",
    "\n",
    "best_params = find_params(rg_xgb, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбираем subsample и colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 36 candidates, totalling 36 fits\n",
      "[CV] colsample_bytree=0.5, subsample=0.5 .............................\n",
      "[CV]  colsample_bytree=0.5, subsample=0.5, score=0.5205217223865368, total=   0.2s\n",
      "[CV] colsample_bytree=0.5, subsample=0.6 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5, subsample=0.6, score=0.5374194916440793, total=   0.2s\n",
      "[CV] colsample_bytree=0.5, subsample=0.7 .............................\n",
      "[CV]  colsample_bytree=0.5, subsample=0.7, score=0.5357534250558018, total=   0.2s\n",
      "[CV] colsample_bytree=0.5, subsample=0.8 .............................\n",
      "[CV]  colsample_bytree=0.5, subsample=0.8, score=0.53911688462111, total=   0.2s\n",
      "[CV] colsample_bytree=0.5, subsample=0.9 .............................\n",
      "[CV]  colsample_bytree=0.5, subsample=0.9, score=0.5379878232221023, total=   0.2s\n",
      "[CV] colsample_bytree=0.5, subsample=1.0 .............................\n",
      "[CV]  colsample_bytree=0.5, subsample=1.0, score=0.5422456468664477, total=   0.2s\n",
      "[CV] colsample_bytree=0.6, subsample=0.5 .............................\n",
      "[CV]  colsample_bytree=0.6, subsample=0.5, score=0.5286554657145994, total=   0.2s\n",
      "[CV] colsample_bytree=0.6, subsample=0.6 .............................\n",
      "[CV]  colsample_bytree=0.6, subsample=0.6, score=0.5289977695741213, total=   0.2s\n",
      "[CV] colsample_bytree=0.6, subsample=0.7 .............................\n",
      "[CV]  colsample_bytree=0.6, subsample=0.7, score=0.5360875557049485, total=   0.2s\n",
      "[CV] colsample_bytree=0.6, subsample=0.8 .............................\n",
      "[CV]  colsample_bytree=0.6, subsample=0.8, score=0.5433720965799873, total=   0.2s\n",
      "[CV] colsample_bytree=0.6, subsample=0.9 .............................\n",
      "[CV]  colsample_bytree=0.6, subsample=0.9, score=0.5378797013529967, total=   0.2s\n",
      "[CV] colsample_bytree=0.6, subsample=1.0 .............................\n",
      "[CV]  colsample_bytree=0.6, subsample=1.0, score=0.5489432661658269, total=   0.2s\n",
      "[CV] colsample_bytree=0.7, subsample=0.5 .............................\n",
      "[CV]  colsample_bytree=0.7, subsample=0.5, score=0.5330825829188187, total=   0.2s\n",
      "[CV] colsample_bytree=0.7, subsample=0.6 .............................\n",
      "[CV]  colsample_bytree=0.7, subsample=0.6, score=0.5277796454676686, total=   0.2s\n",
      "[CV] colsample_bytree=0.7, subsample=0.7 .............................\n",
      "[CV]  colsample_bytree=0.7, subsample=0.7, score=0.5284826911548673, total=   0.2s\n",
      "[CV] colsample_bytree=0.7, subsample=0.8 .............................\n",
      "[CV]  colsample_bytree=0.7, subsample=0.8, score=0.5448933765664267, total=   0.2s\n",
      "[CV] colsample_bytree=0.7, subsample=0.9 .............................\n",
      "[CV]  colsample_bytree=0.7, subsample=0.9, score=0.5290007867419935, total=   0.2s\n",
      "[CV] colsample_bytree=0.7, subsample=1.0 .............................\n",
      "[CV]  colsample_bytree=0.7, subsample=1.0, score=0.5492700099910954, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, subsample=0.5 .............................\n",
      "[CV]  colsample_bytree=0.8, subsample=0.5, score=0.529075599400991, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, subsample=0.6 .............................\n",
      "[CV]  colsample_bytree=0.8, subsample=0.6, score=0.5407024354351142, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, subsample=0.7 .............................\n",
      "[CV]  colsample_bytree=0.8, subsample=0.7, score=0.535934290351928, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, subsample=0.8 .............................\n",
      "[CV]  colsample_bytree=0.8, subsample=0.8, score=0.5487967519402525, total=   0.2s\n",
      "[CV] colsample_bytree=0.8, subsample=0.9 .............................\n",
      "[CV]  colsample_bytree=0.8, subsample=0.9, score=0.531588752866677, total=   0.3s\n",
      "[CV] colsample_bytree=0.8, subsample=1.0 .............................\n",
      "[CV]  colsample_bytree=0.8, subsample=1.0, score=0.541332026696359, total=   0.3s\n",
      "[CV] colsample_bytree=0.9, subsample=0.5 .............................\n",
      "[CV]  colsample_bytree=0.9, subsample=0.5, score=0.5308862866469283, total=   0.2s\n",
      "[CV] colsample_bytree=0.9, subsample=0.6 .............................\n",
      "[CV]  colsample_bytree=0.9, subsample=0.6, score=0.5392617637966135, total=   0.2s\n",
      "[CV] colsample_bytree=0.9, subsample=0.7 .............................\n",
      "[CV]  colsample_bytree=0.9, subsample=0.7, score=0.5414240072333582, total=   0.3s\n",
      "[CV] colsample_bytree=0.9, subsample=0.8 .............................\n",
      "[CV]  colsample_bytree=0.9, subsample=0.8, score=0.5480276592038187, total=   0.3s\n",
      "[CV] colsample_bytree=0.9, subsample=0.9 .............................\n",
      "[CV]  colsample_bytree=0.9, subsample=0.9, score=0.5582693010594895, total=   0.3s\n",
      "[CV] colsample_bytree=0.9, subsample=1.0 .............................\n",
      "[CV]  colsample_bytree=0.9, subsample=1.0, score=0.5485614824845342, total=   0.3s\n",
      "[CV] colsample_bytree=1.0, subsample=0.5 .............................\n",
      "[CV]  colsample_bytree=1.0, subsample=0.5, score=0.5368249648844905, total=   0.3s\n",
      "[CV] colsample_bytree=1.0, subsample=0.6 .............................\n",
      "[CV]  colsample_bytree=1.0, subsample=0.6, score=0.5500234809263727, total=   0.3s\n",
      "[CV] colsample_bytree=1.0, subsample=0.7 .............................\n",
      "[CV]  colsample_bytree=1.0, subsample=0.7, score=0.538919250144197, total=   0.3s\n",
      "[CV] colsample_bytree=1.0, subsample=0.8 .............................\n",
      "[CV]  colsample_bytree=1.0, subsample=0.8, score=0.5484354987477849, total=   0.3s\n",
      "[CV] colsample_bytree=1.0, subsample=0.9 .............................\n",
      "[CV]  colsample_bytree=1.0, subsample=0.9, score=0.5434299208713378, total=   0.3s\n",
      "[CV] colsample_bytree=1.0, subsample=1.0 .............................\n",
      "[CV]  colsample_bytree=1.0, subsample=1.0, score=0.5478259207064616, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    8.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.9, 'gamma': 0.0, 'learning_rate': 0.03, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 20, 'missing': None, 'n_estimators': 50, 'n_jobs': 4, 'nthread': None, 'objective': 'reg:linear', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "rg_xgb = xgb.XGBRegressor(**best_params)\n",
    "\n",
    "param_grid = {\n",
    "    'subsample': np.linspace(0.5, 1, 6),\n",
    "    'colsample_bytree': np.linspace(0.5, 1, 6)\n",
    "}\n",
    "\n",
    "best_params = find_params(rg_xgb, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбираем регуляризацию: reg_lambda и reg_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 25 candidates, totalling 25 fits\n",
      "[CV] reg_alpha=0, reg_lambda=0 .......................................\n",
      "[CV]  reg_alpha=0, reg_lambda=0, score=0.5802772150198364, total=   0.3s\n",
      "[CV] reg_alpha=0, reg_lambda=0.0001 ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=0, reg_lambda=0.0001, score=0.5802730920619759, total=   0.4s\n",
      "[CV] reg_alpha=0, reg_lambda=0.001 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=0, reg_lambda=0.001, score=0.5802115459384869, total=   0.3s\n",
      "[CV] reg_alpha=0, reg_lambda=0.1 .....................................\n",
      "[CV]  reg_alpha=0, reg_lambda=0.1, score=0.568522256983355, total=   0.4s\n",
      "[CV] reg_alpha=0, reg_lambda=1 .......................................\n",
      "[CV]  reg_alpha=0, reg_lambda=1, score=0.5582693010594895, total=   0.3s\n",
      "[CV] reg_alpha=0.0001, reg_lambda=0 ..................................\n",
      "[CV]  reg_alpha=0.0001, reg_lambda=0, score=0.5802772159353369, total=   0.4s\n",
      "[CV] reg_alpha=0.0001, reg_lambda=0.0001 .............................\n",
      "[CV]  reg_alpha=0.0001, reg_lambda=0.0001, score=0.5802730977742007, total=   0.3s\n",
      "[CV] reg_alpha=0.0001, reg_lambda=0.001 ..............................\n",
      "[CV]  reg_alpha=0.0001, reg_lambda=0.001, score=0.5802115459384869, total=   0.3s\n",
      "[CV] reg_alpha=0.0001, reg_lambda=0.1 ................................\n",
      "[CV]  reg_alpha=0.0001, reg_lambda=0.1, score=0.5685222552167792, total=   0.3s\n",
      "[CV] reg_alpha=0.0001, reg_lambda=1 ..................................\n",
      "[CV]  reg_alpha=0.0001, reg_lambda=1, score=0.5582693010594895, total=   0.3s\n",
      "[CV] reg_alpha=0.001, reg_lambda=0 ...................................\n",
      "[CV]  reg_alpha=0.001, reg_lambda=0, score=0.5802772159353369, total=   0.4s\n",
      "[CV] reg_alpha=0.001, reg_lambda=0.0001 ..............................\n",
      "[CV]  reg_alpha=0.001, reg_lambda=0.0001, score=0.5802730977742007, total=   0.3s\n",
      "[CV] reg_alpha=0.001, reg_lambda=0.001 ...............................\n",
      "[CV]  reg_alpha=0.001, reg_lambda=0.001, score=0.5802115459384869, total=   0.3s\n",
      "[CV] reg_alpha=0.001, reg_lambda=0.1 .................................\n",
      "[CV]  reg_alpha=0.001, reg_lambda=0.1, score=0.568522256983355, total=   0.3s\n",
      "[CV] reg_alpha=0.001, reg_lambda=1 ...................................\n",
      "[CV]  reg_alpha=0.001, reg_lambda=1, score=0.5582693002594811, total=   0.3s\n",
      "[CV] reg_alpha=0.1, reg_lambda=0 .....................................\n",
      "[CV]  reg_alpha=0.1, reg_lambda=0, score=0.5802771646867979, total=   0.3s\n",
      "[CV] reg_alpha=0.1, reg_lambda=0.0001 ................................\n",
      "[CV]  reg_alpha=0.1, reg_lambda=0.0001, score=0.5802730565156269, total=   0.4s\n",
      "[CV] reg_alpha=0.1, reg_lambda=0.001 .................................\n",
      "[CV]  reg_alpha=0.1, reg_lambda=0.001, score=0.5802115058136206, total=   0.3s\n",
      "[CV] reg_alpha=0.1, reg_lambda=0.1 ...................................\n",
      "[CV]  reg_alpha=0.1, reg_lambda=0.1, score=0.5685222175681542, total=   0.3s\n",
      "[CV] reg_alpha=0.1, reg_lambda=1 .....................................\n",
      "[CV]  reg_alpha=0.1, reg_lambda=1, score=0.5582692736661747, total=   0.3s\n",
      "[CV] reg_alpha=1, reg_lambda=0 .......................................\n",
      "[CV]  reg_alpha=1, reg_lambda=0, score=0.5802767685738645, total=   0.3s\n",
      "[CV] reg_alpha=1, reg_lambda=0.0001 ..................................\n",
      "[CV]  reg_alpha=1, reg_lambda=0.0001, score=0.580272672546455, total=   0.3s\n",
      "[CV] reg_alpha=1, reg_lambda=0.001 ...................................\n",
      "[CV]  reg_alpha=1, reg_lambda=0.001, score=0.5802110836154026, total=   0.4s\n",
      "[CV] reg_alpha=1, reg_lambda=0.1 .....................................\n",
      "[CV]  reg_alpha=1, reg_lambda=0.1, score=0.5685218097647939, total=   0.3s\n",
      "[CV] reg_alpha=1, reg_lambda=1 .......................................\n",
      "[CV]  reg_alpha=1, reg_lambda=1, score=0.5582690405787161, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    8.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.9, 'gamma': 0.0, 'learning_rate': 0.03, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 20, 'missing': None, 'n_estimators': 50, 'n_jobs': 4, 'nthread': None, 'objective': 'reg:linear', 'random_state': 0, 'reg_alpha': 0.0001, 'reg_lambda': 0, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "rg_xgb = xgb.XGBRegressor(**best_params)\n",
    "\n",
    "param_grid = {\n",
    "    'reg_alpha': [0, 0.0001, 0.001, 0.1, 1],\n",
    "    'reg_lambda': [0, 0.0001, 0.001, 0.1, 1]\n",
    "}\n",
    "\n",
    "best_params = find_params(rg_xgb, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Уменьшим learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains new labels: [ 35311  52500  55993  62383  75000  75500  79900  80500  89471  91300\n  92000  93500  94000  94500  94750 101000 110500 111250 112500 114500\n 116500 121000 121500 126175 128900 128950 134450 134800 135960 136900\n 138887 139600 143750 144500 146800 147500 150500 150900 153575 154900\n 156500 157500 162500 163990 164900 167240 171500 173733 176432 176485\n 178740 178900 179400 181134 182000 183900 185750 186000 187100 187750\n 189950 192140 192500 195400 201800 202665 206000 208300 213490 214900\n 216000 216837 222500 235128 243000 244400 244600 245000 245350 245500\n 246578 248900 249700 255000 255500 259500 262280 263000 263435 264132\n 265900 274300 275500 281213 283463 286000 287000 294000 305000 313000\n 315750 326000 337000 337500 339750 348000 367294 369900 375000 377500\n 378500 380000 395000 402861 410000 430000 438780 451950 556581]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8567b5d40802>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrg_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrg_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    483\u001b[0m                 DMatrix(x[0], label=self._le.transform(x[1]),\n\u001b[1;32m    484\u001b[0m                         missing=self.missing, nthread=self.n_jobs)\n\u001b[0;32m--> 485\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m             \u001b[0mnevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    483\u001b[0m                 DMatrix(x[0], label=self._le.transform(x[1]),\n\u001b[1;32m    484\u001b[0m                         missing=self.missing, nthread=self.n_jobs)\n\u001b[0;32m--> 485\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m             \u001b[0mnevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y contains new labels: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains new labels: [ 35311  52500  55993  62383  75000  75500  79900  80500  89471  91300\n  92000  93500  94000  94500  94750 101000 110500 111250 112500 114500\n 116500 121000 121500 126175 128900 128950 134450 134800 135960 136900\n 138887 139600 143750 144500 146800 147500 150500 150900 153575 154900\n 156500 157500 162500 163990 164900 167240 171500 173733 176432 176485\n 178740 178900 179400 181134 182000 183900 185750 186000 187100 187750\n 189950 192140 192500 195400 201800 202665 206000 208300 213490 214900\n 216000 216837 222500 235128 243000 244400 244600 245000 245350 245500\n 246578 248900 249700 255000 255500 259500 262280 263000 263435 264132\n 265900 274300 275500 281213 283463 286000 287000 294000 305000 313000\n 315750 326000 337000 337500 339750 348000 367294 369900 375000 377500\n 378500 380000 395000 402861 410000 430000 438780 451950 556581]"
     ]
    }
   ],
   "source": [
    "best_params['learning_rate'] = 0.01\n",
    "best_params['n_estimators'] = 500\n",
    "\n",
    "rg_xgb = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "rg_xgb.fit(X_train, y_train, eval_set=[[X_train, y_train], [X_test, y_test]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
