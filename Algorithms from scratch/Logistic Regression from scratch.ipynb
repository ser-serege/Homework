{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]\n",
    "y = (iris.target != 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_regression(X, y,  num_iter = 100,  learning_rate = 1, X_test = None, probs = True):\n",
    "\n",
    "    def sigmoid(X, weight): # final activation function \n",
    "        z = np.dot(X, weight) # product of matrix X and weights \n",
    "        return 1 / (1 + np.exp(-z)) # sigmoid function to predict probability  \n",
    "\n",
    "    def log_likelihood(X, y, weights): #\n",
    "        z = np.dot(X, weights) # product of matrix X and weights \n",
    "        ll = np.sum( y * z - np.log(1 + np.exp(z)) )\n",
    "        return ll\n",
    "\n",
    "    def gradient_ascent(X, sigmoida, y): # \n",
    "        return np.dot(X.T, y - sigmoida)\n",
    "\n",
    "    def update_weight_mle(weight, learning_rate, gradient):\n",
    "        return weight + learning_rate * gradient\n",
    "\n",
    "    def fit(X, y, num_iter ,  learning_rate ):\n",
    "        intercept = np.ones((X.shape[0], 1)) # initialize intercept  \n",
    "        X = np.concatenate((intercept, X), axis=1) # put intercept into dataset\n",
    "        theta = np.zeros(X.shape[1]) # initialize weights\n",
    "        for i in range(num_iter): # define num of iterations\n",
    "            sigmoida = sigmoid(X, theta)  # 1 / (1 + np.exp(- (np.dot(X, weight)))) - calc answers\n",
    "            gradient = gradient_ascent(X, sigmoida, y) #np.dot(X.T, (h - y)) / y.size - calc gradient\n",
    "            theta = update_weight_mle(theta, learning_rate, gradient) # weight + learning_rate * gradient - make step\n",
    "        return theta, intercept\n",
    "\n",
    "    def predict_proba(X, theta): # define probability\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.concatenate((intercept, X), axis=1) # concat with intercept\n",
    "        return sigmoid(X, theta)\n",
    "\n",
    "    def predict(X, theta, threshold=0.5): # define 1 or 0 with threshold\n",
    "        return predict_proba(X, theta) >= threshold \n",
    "    \n",
    "    theta, intercept = fit(X, y, num_iter, learning_rate)\n",
    "\n",
    "    if probs:    \n",
    "        result = predict_proba(X, theta)\n",
    "\n",
    "        try:\n",
    "            result2 = predict_proba(X_test, theta)\n",
    "            print('Train predicted')\n",
    "            print('Test predicted')\n",
    "            return result, result2\n",
    "        except: result2 = None\n",
    "\n",
    "        print('Train predicted')\n",
    "        print('Test not predicted')\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        result = predict(X, theta)\n",
    "\n",
    "        try:\n",
    "            result2 = predict(X_test, theta)\n",
    "            print('Train predicted')\n",
    "            print('Test predicted')\n",
    "            return result, result2\n",
    "        except: result2 = None\n",
    "\n",
    "        print('Train predicted')\n",
    "        print('Test not predicted')\n",
    "\n",
    "    return result, result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, train_size = 0.7):\n",
    "    ind = int(len(X) * train_size)\n",
    "\n",
    "    X_train = X[:ind]\n",
    "    y_train = y[:ind]\n",
    "\n",
    "    X_test = X[ind:]\n",
    "    y_test = y[ind:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train predicted\n",
      "Test predicted\n",
      "train= 0.9904761904761905\n",
      "test= 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, train_size = 0.7)\n",
    "\n",
    "result_train, result_test = Logistic_regression(X_train, y_train , X_test= X_test, probs= False)\n",
    "print('train=', (result_train == y_train).mean())\n",
    "print('test=', (result_test == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train predicted\n",
      "Test not predicted\n",
      "train= 0.9904761904761905\n",
      "test= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "result_train, result_test = Logistic_regression(X_train, y_train , X_test= False, probs= False)\n",
    "print('train=', (result_train == y_train).mean())\n",
    "print('test=', (result_test == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train= 0.9904761904761905\n",
      "test= 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "result_sklearn_train = lr.predict(X_train)\n",
    "result_sklearn_test = lr.predict(X_test)\n",
    "\n",
    "print('train=', (result_sklearn_train == y_train).mean())\n",
    "print('test=',  (result_sklearn_test == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
