{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import timedelta\n",
    "from pandas import pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD SAVED DATA FROM PREVIOUS ENGEENIRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "update1 =pd.read_csv('update1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "update1= update1.loc[update1['Group'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIVOT TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = pivot_table(update1, values=['7_days', '60_days', '1_month', '2_month', '3_month', 'spent_on_pos', 'total_spent', 'Cashback', 'total_earn', 'amount_in_rub' ],\n",
    "                    index=['cl_id'], aggfunc=np.sum)\n",
    "month1 = pivot_table(update1, values=['spent_on_pos', 'total_spent', 'Cashback', 'total_earn', 'amount_in_rub' ],\n",
    "                    index=['cl_id'], aggfunc=lambda Cashback: len(Cashback.unique()))\n",
    "\n",
    "\n",
    "spent_on_open_date = pivot_table(update1, values='amount_in_rub', \n",
    "                    index=['cl_id'], columns=['PERIOD_y'], aggfunc=lambda amount_in_rub: len(amount_in_rub.unique()))\n",
    "\n",
    "\n",
    "day = pivot_table(update1, values='spent_on_pos', \n",
    "                    index=['cl_id'], columns=['Day1'], aggfunc=lambda amount_in_rub: len(amount_in_rub.unique()))\n",
    "\n",
    "\n",
    "\n",
    "trx = pivot_table(update1, values='amount_in_rub', \n",
    "                    index=['cl_id'], columns=['trx_category'], aggfunc=np.mean)\n",
    "\n",
    "\n",
    "\n",
    "group_mcc = pivot_table(update1, values='amount_in_rub', \n",
    "                    index=['cl_id'], columns=['Group'], aggfunc=lambda amount_in_rub: len(amount_in_rub.unique()))\n",
    "\n",
    "\n",
    "region = pivot_table(update1, values='spent_on_pos', \n",
    "                    index=['cl_id'], columns=['region'], aggfunc=lambda amount_in_rub: len(amount_in_rub.unique()))\n",
    "\n",
    "channel_type = pivot_table(update1, values='spent_on_pos', \n",
    "                    index=['cl_id'], columns=['channel_type'], aggfunc=lambda amount_in_rub: len(amount_in_rub.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "channel_type = pivot_table(update1, values='spent_on_pos', \n",
    "                    index=['cl_id'], columns=['channel_type'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags_qwe_ewq = update1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1= pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1['cl_id']=flags_qwe_ewq['cl_id']\n",
    "new1['target_flag']=flags_qwe_ewq['target_flag']\n",
    "new1['target_sum']=flags_qwe_ewq['target_sum']\n",
    "new1['total_usage']=flags_qwe_ewq['qwe']\n",
    "new1['POS_usage']=flags_qwe_ewq['ewq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1=new1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1=new1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1[month.columns] =month\n",
    "new1[month1.columns] =month1\n",
    "new1[spent_on_open_date.columns] =spent_on_open_date\n",
    "new1[day.columns] =day\n",
    "new1[trx.columns] =trx\n",
    "new1[group_mcc.columns] =group_mcc\n",
    "new1[region.columns] =region\n",
    "new1[channel_type.columns] =channel_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=data_train[data_train['target_flag']!='p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.target_flag.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "data_train.target_flag=data_train.target_flag.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "random_splitter = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state=777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=777)\n",
    "\n",
    "for train_index, test_index in splitter.split(data_train, data_train.target_flag):\n",
    "    d_train = data_train.iloc[train_index]\n",
    "    d_test = data_train.iloc[test_index]\n",
    "    \n",
    "    y_train = data_train['target_flag'].iloc[train_index]\n",
    "    y_test = data_train['target_flag'].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=d_train\n",
    "data_test=d_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COUNTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(df_train, df_test, col, target_col):\n",
    "    category_val_dict = (\n",
    "        df_train[df_train[target_col] == 1][col].value_counts()\n",
    "        /\n",
    "        df_train[col].value_counts()\n",
    "    ).to_dict()\n",
    "    df_train[col + '_counts'] = df_train[col].apply(category_val_dict.get)\n",
    "    df_test[col + '_counts'] = df_test[col].apply(category_val_dict.get)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "columns_to_get_counts = ['total_usage', 'POS_usage', '1_month', '2_month', '3_month', '60_days', '7_days',\n",
    "  'Asia', 'CIS', 'Cis', 'Russia', 'asia', 'cheap', 'expencive', 'norm']\n",
    "    \n",
    "for col_get_prob in columns_to_get_counts:\n",
    "    data_train, data_test = get_counts(data_train, data_test, col_get_prob, 'target_flag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_woe_v1(df_train, df_test, col, target_col):\n",
    "    all_good = len(df_train[df_train[target_col] == 1][col])\n",
    "    all_bad = len(df_train[df_train[target_col] == 0][col])\n",
    "    odds_series = (\n",
    "        df_train[df_train[target_col] == 1][col].value_counts()\n",
    "        /\n",
    "        df_train[df_train[target_col] == 0][col].value_counts()\n",
    "    )\n",
    "    odds_series = odds_series / all_good * all_bad\n",
    "    category_woe_dict = np.log(odds_series).to_dict()\n",
    "    df_train[col + '_woe'] = df_train[col].apply(category_woe_dict.get)\n",
    "    df_test[col + '_woe'] = df_test[col].apply(category_woe_dict.get)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_get_prob in columns_to_get_counts:\n",
    "    data_train, data_test = get_woe_v1(data_train, data_test, col_get_prob, 'target_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=data_train['target_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1=data_train.fillna(0)\n",
    "x_test1=data_test.fillna(0)\n",
    "cat_feat = list(x_train1.dtypes[x_train1.dtypes == object].index)\n",
    "x_train1=x_train1.drop(columns=cat_feat)\n",
    "x_test1=x_test1.drop(columns=cat_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train1['target_flag']\n",
    "del x_test1['target_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train1['cl_id']\n",
    "del x_test1['cl_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "x_test1 = pd.DataFrame(StandardScaler().fit_transform(x_test1), columns=x_test1.columns)\n",
    "x_train1 = pd.DataFrame(StandardScaler().fit_transform(x_train1), columns=x_train1.columns)\n",
    "del x_train1['index']\n",
    "del x_test1['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  1.0 Test:  0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm = svm.SVC()\n",
    "svm.fit(x_train1, y_train) \n",
    "\n",
    "y_pred_svm = svm.predict(x_test1)\n",
    "y_pred_svm_train = svm.predict(x_train1)\n",
    "roc_auc_train = np.round(roc_auc_score(y_train, y_pred_svm_train), 2)\n",
    "roc_auc_test = np.round(roc_auc_score(y_test, y_pred_svm), 2)\n",
    "print(\"Train: \", roc_auc_train , \"Test: \", roc_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  1.0 Test:  0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm = svm.SVC( kernel='linear')\n",
    "svm.fit(x_train1, y_train) \n",
    "\n",
    "y_pred_svm1 = svm.predict(x_test1)\n",
    "y_pred_svm_train1 = svm.predict(x_train1)\n",
    "\n",
    "roc_auc_train1 = np.round(roc_auc_score(y_train, y_pred_svm_train1), 2)\n",
    "roc_auc_test1 = np.round(roc_auc_score(y_test, y_pred_svm1), 2)\n",
    "print(\"Train: \", roc_auc_train1, \"Test: \", roc_auc_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  1.0 Test:  0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(x_train1, y_train)\n",
    "clf_pred = clf_lr.predict(x_test1)\n",
    "clf_pred1 = clf_lr.predict(x_train1)\n",
    "roc_auc_train = np.round(roc_auc_score(y_train, clf_pred1), 2)\n",
    "roc_auc_test = np.round(roc_auc_score(y_test, clf_pred), 2)\n",
    "print(\"Train: \", roc_auc_train , \"Test: \", roc_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
